# Queue System Configuration Example
# Copy this file to .env and configure for your environment

# ============================================
# Queue System Settings
# ============================================

# Enable queue-based processing (set to true to use SQS instead of goroutines)
QUEUE_ENABLED=true

# Maximum number of messages to receive per poll (1-10)
# Higher values improve throughput but may cause uneven load distribution
QUEUE_MAX_MESSAGES=10

# Long polling wait time in seconds (0-20)
# Use 20 for maximum efficiency and reduced empty receives
QUEUE_WAIT_TIME_SECONDS=20

# Message visibility timeout in seconds
# Should be 2-3x your average execution time to allow for retries
# Messages become visible again after this timeout if not deleted
QUEUE_VISIBILITY_TIMEOUT=30

# Maximum number of retries before sending message to DLQ
# After exceeding this count, message is automatically moved to DLQ
QUEUE_MAX_RETRIES=3

# Maximum time to process a single message (in seconds)
# Processing will be cancelled after this timeout
QUEUE_PROCESS_TIMEOUT=300

# Interval between polls when no messages are received (in seconds)
# Lower values reduce latency but increase API calls
QUEUE_POLL_INTERVAL=1

# Number of concurrent message processors per worker pod
# Adjust based on CPU/memory resources
QUEUE_CONCURRENT_WORKERS=10

# Automatically delete message after successful processing
# Set to false if you want to manually manage message deletion
QUEUE_DELETE_AFTER_PROCESS=true

# ============================================
# AWS Configuration
# ============================================

# AWS Region
AWS_REGION=us-east-1

# AWS Credentials (not needed if using IAM roles)
# Leave empty when using IAM roles in EKS/EC2
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

# AWS Endpoint (for LocalStack or custom endpoints)
# Leave empty for production AWS
# For LocalStack: http://localhost:4566
AWS_ENDPOINT=

# SQS Queue URLs
# Main queue for workflow executions
AWS_SQS_QUEUE_URL=https://sqs.us-east-1.amazonaws.com/123456789/rflow-executions

# Dead-letter queue for failed messages
AWS_SQS_DLQ_URL=https://sqs.us-east-1.amazonaws.com/123456789/rflow-executions-dlq

# S3 Bucket (for future use)
AWS_S3_BUCKET=rflow-artifacts

# ============================================
# LocalStack Configuration (Development)
# ============================================

# Uncomment these for local development with LocalStack
# AWS_ENDPOINT=http://localhost:4566
# AWS_REGION=us-east-1
# AWS_ACCESS_KEY_ID=test
# AWS_SECRET_ACCESS_KEY=test
# AWS_SQS_QUEUE_URL=http://localhost:4566/000000000000/rflow-executions
# AWS_SQS_DLQ_URL=http://localhost:4566/000000000000/rflow-executions-dlq

# ============================================
# Worker Configuration
# ============================================

# Worker concurrency (for non-queue mode)
WORKER_CONCURRENCY=10

# Maximum concurrent executions per tenant
# Prevents a single tenant from consuming all worker resources
WORKER_MAX_CONCURRENCY_PER_TENANT=10

# Worker health check port
WORKER_HEALTH_PORT=8081

# ============================================
# Database Configuration
# ============================================

DB_HOST=localhost
DB_PORT=5433
DB_USER=postgres
DB_PASSWORD=postgres
DB_NAME=rflow
DB_SSLMODE=disable

# ============================================
# Redis Configuration
# ============================================

REDIS_ADDRESS=localhost:6379
REDIS_PASSWORD=
REDIS_DB=0

# ============================================
# Server Configuration
# ============================================

SERVER_ADDRESS=:8080
APP_ENV=development

# ============================================
# Ory Kratos Configuration
# ============================================

KRATOS_PUBLIC_URL=http://localhost:4433
KRATOS_ADMIN_URL=http://localhost:4434

# ============================================
# Scaling Recommendations
# ============================================

# Production (High Load):
# QUEUE_ENABLED=true
# QUEUE_MAX_MESSAGES=10
# QUEUE_WAIT_TIME_SECONDS=20
# QUEUE_VISIBILITY_TIMEOUT=60
# QUEUE_MAX_RETRIES=5
# QUEUE_PROCESS_TIMEOUT=600
# QUEUE_CONCURRENT_WORKERS=20

# Production (Medium Load):
# QUEUE_ENABLED=true
# QUEUE_MAX_MESSAGES=10
# QUEUE_WAIT_TIME_SECONDS=20
# QUEUE_VISIBILITY_TIMEOUT=30
# QUEUE_MAX_RETRIES=3
# QUEUE_PROCESS_TIMEOUT=300
# QUEUE_CONCURRENT_WORKERS=10

# Development:
# QUEUE_ENABLED=false  # Use goroutines for simple testing
# Or use LocalStack for SQS testing

# ============================================
# Notes
# ============================================

# 1. Visibility Timeout: Set to 2-3x your average execution time
#    - If executions take 10s on average, set to 20-30s
#    - If executions take 60s on average, set to 120-180s

# 2. Process Timeout: Set higher than your longest expected execution
#    - Should be at least 2x your p99 execution time
#    - Default of 5 minutes (300s) is reasonable for most workflows

# 3. Max Retries: Balance between retry attempts and DLQ speed
#    - 3 retries is usually sufficient for transient failures
#    - Increase to 5-10 for flaky external services
#    - Decrease to 1-2 for critical failures that need immediate attention

# 4. Concurrent Workers: Scale based on resources
#    - CPU-bound workflows: Match CPU cores (e.g., 4-8 workers)
#    - I/O-bound workflows: Use more workers (e.g., 20-50 workers)
#    - Monitor CPU and memory usage to find optimal value

# 5. Queue Enabled: Enable for production horizontal scaling
#    - Set to false for simple single-instance deployments
#    - Set to true when running multiple worker pods
#    - Required for proper load distribution across workers
